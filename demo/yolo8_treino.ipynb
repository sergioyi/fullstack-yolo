{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Esse c√≥digo gera as m√©tricas do treino do coc... com o yolo8"
      ],
      "metadata": {
        "id": "xNIgjisH_VA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --upgrade --quiet"
      ],
      "metadata": {
        "id": "tYEVRiD3CG55"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rKA4qv7D_QkA",
        "outputId": "8f243539-8dba-45ca-f7fd-a45774454807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 115MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.160 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco128.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_coco128, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train/yolov8_coco128, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "WARNING ‚ö†Ô∏è Dataset 'coco128.yaml' images not found, missing path '/content/datasets/coco128/images/train2017'\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to '/content/datasets/coco128.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.66M/6.66M [00:00<00:00, 124MB/s]\n",
            "Unzipping /content/datasets/coco128.zip to /content/datasets/coco128...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 263/263 [00:00<00:00, 2636.00file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (1.0s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 20.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1381.9¬±500.6 MB/s, size: 50.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 1067.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1430.1¬±616.7 MB/s, size: 52.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/train/yolov8_coco128/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov8_coco128\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10         0G      1.161       1.33      1.184         78        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:29<00:00, 18.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:50<00:00, 12.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.641       0.55       0.61       0.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10         0G      1.146       1.28      1.181         97        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:14<00:00, 16.81s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:43<00:00, 10.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.651      0.581      0.628      0.467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10         0G      1.144      1.299      1.188        110        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:10<00:00, 16.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:43<00:00, 10.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.648      0.589      0.638      0.479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10         0G      1.174      1.318      1.198         95        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:12<00:00, 16.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:46<00:00, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.688      0.569      0.652      0.492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10         0G      1.105      1.277      1.158         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:18<00:00, 17.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 11.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.667      0.624      0.666      0.506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10         0G      1.118      1.223      1.161         99        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:13<00:00, 16.68s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:46<00:00, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.675      0.635      0.673      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10         0G      1.093      1.183      1.162        191        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:19<00:00, 17.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 11.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.677      0.634      0.678      0.517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10         0G      1.092      1.159      1.149        150        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:18<00:00, 17.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929       0.69      0.623       0.69      0.528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10         0G      1.079       1.14       1.17        100        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:14<00:00, 16.87s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:43<00:00, 10.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.696      0.623      0.694      0.529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10         0G       1.08      1.098      1.148        112        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:14<00:00, 16.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:47<00:00, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.694      0.622      0.689      0.527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.508 hours.\n",
            "Optimizer stripped from runs/train/yolov8_coco128/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/train/yolov8_coco128/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/train/yolov8_coco128/weights/best.pt...\n",
            "Ultralytics 8.3.160 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:37<00:00,  9.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.695      0.623      0.693      0.529\n",
            "                person         61        254      0.842       0.65      0.777      0.566\n",
            "               bicycle          3          6       0.92      0.333      0.361       0.32\n",
            "                   car         12         46      0.697      0.239      0.321      0.195\n",
            "            motorcycle          4          5      0.682      0.863      0.938       0.73\n",
            "              airplane          5          6      0.801          1      0.995      0.803\n",
            "                   bus          5          7      0.844      0.714      0.721      0.664\n",
            "                 train          3          3      0.756          1      0.995      0.852\n",
            "                 truck          5         12      0.856        0.5      0.546      0.381\n",
            "                  boat          2          6      0.488      0.333      0.613      0.379\n",
            "         traffic light          4         14      0.451      0.143      0.179      0.137\n",
            "             stop sign          2          2       0.72          1      0.995      0.647\n",
            "                 bench          5          9       0.65      0.333      0.631      0.455\n",
            "                  bird          2         16      0.924       0.75      0.947      0.639\n",
            "                   cat          4          4      0.881          1      0.995      0.755\n",
            "                   dog          9          9      0.622      0.889      0.923       0.75\n",
            "                 horse          1          2      0.562          1      0.995      0.597\n",
            "              elephant          4         17      0.743      0.882      0.906      0.738\n",
            "                  bear          1          1      0.578          1      0.995      0.995\n",
            "                 zebra          2          4      0.864          1      0.995      0.972\n",
            "               giraffe          4          9      0.989          1      0.995      0.768\n",
            "              backpack          4          6      0.626      0.333      0.402      0.285\n",
            "              umbrella          4         18       0.62      0.611      0.692      0.475\n",
            "               handbag          9         19      0.735      0.158      0.318      0.169\n",
            "                   tie          6          7      0.679      0.714       0.75      0.538\n",
            "              suitcase          2          4      0.748          1      0.895      0.637\n",
            "               frisbee          5          5      0.712        0.8      0.759      0.679\n",
            "                  skis          1          1      0.859          1      0.995      0.497\n",
            "             snowboard          2          7      0.444      0.571       0.75      0.545\n",
            "           sports ball          6          6      0.652      0.319      0.485      0.332\n",
            "                  kite          2         10      0.701        0.4      0.605      0.213\n",
            "          baseball bat          4          4      0.624       0.25      0.414      0.248\n",
            "        baseball glove          4          7      0.864      0.429      0.431      0.304\n",
            "            skateboard          3          5      0.788        0.6      0.621      0.426\n",
            "         tennis racket          5          7      0.491      0.429      0.588      0.369\n",
            "                bottle          6         18      0.591      0.333      0.395      0.259\n",
            "            wine glass          5         16       0.61      0.375      0.623      0.361\n",
            "                   cup         10         36      0.665      0.389        0.5      0.368\n",
            "                  fork          6          6      0.596      0.167      0.268      0.235\n",
            "                 knife          7         16      0.662      0.625      0.623      0.374\n",
            "                 spoon          5         22      0.644      0.329      0.401      0.245\n",
            "                  bowl          9         28      0.592       0.75      0.756      0.613\n",
            "                banana          1          1          0          0      0.249     0.0321\n",
            "              sandwich          2          2      0.782          1      0.995      0.995\n",
            "                orange          1          4      0.787          1      0.895      0.607\n",
            "              broccoli          4         11      0.558      0.235      0.336      0.247\n",
            "                carrot          3         24      0.643      0.833      0.808      0.515\n",
            "               hot dog          1          2      0.512          1      0.995      0.995\n",
            "                 pizza          5          5      0.872          1      0.995      0.893\n",
            "                 donut          2         14      0.556          1      0.913      0.828\n",
            "                  cake          4          4       0.84          1      0.995      0.921\n",
            "                 chair          9         35      0.571      0.533      0.505       0.32\n",
            "                 couch          5          6      0.826      0.667        0.8      0.591\n",
            "          potted plant          9         14      0.747      0.714      0.764      0.515\n",
            "                   bed          3          3       0.91          1      0.995      0.858\n",
            "          dining table         10         13      0.513      0.615       0.61      0.486\n",
            "                toilet          2          2          1      0.906      0.995      0.946\n",
            "                    tv          2          2        0.8          1      0.995      0.895\n",
            "                laptop          2          3      0.779      0.667      0.806      0.716\n",
            "                 mouse          2          2          1          0      0.066     0.0066\n",
            "                remote          5          8      0.778        0.5      0.588      0.508\n",
            "            cell phone          5          8       0.32      0.125      0.104     0.0777\n",
            "             microwave          3          3      0.683      0.667      0.913      0.749\n",
            "                  oven          5          5      0.502        0.4       0.52      0.383\n",
            "                  sink          4          6      0.406      0.167      0.308      0.192\n",
            "          refrigerator          5          5      0.676      0.423      0.795       0.64\n",
            "                  book          6         29      0.597      0.204      0.395      0.197\n",
            "                 clock          8          9      0.778      0.781      0.887      0.772\n",
            "                  vase          2          2      0.424          1      0.995      0.945\n",
            "              scissors          1          1          1          0      0.166     0.0221\n",
            "            teddy bear          6         21       0.68      0.619      0.704      0.492\n",
            "            toothbrush          2          5          1      0.978      0.995      0.685\n",
            "Speed: 5.5ms preprocess, 267.7ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/train/yolov8_coco128\u001b[0m\n",
            "Ultralytics 8.3.160 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1274.4¬±417.2 MB/s, size: 44.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:31<00:00,  3.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.683      0.623      0.692      0.526\n",
            "                person         61        254      0.846      0.671      0.779      0.566\n",
            "               bicycle          3          6      0.889      0.333       0.37      0.326\n",
            "                   car         12         46      0.662      0.217      0.314      0.192\n",
            "            motorcycle          4          5      0.684      0.873      0.938       0.73\n",
            "              airplane          5          6      0.797          1      0.995      0.803\n",
            "                   bus          5          7      0.732      0.714      0.721      0.661\n",
            "                 train          3          3      0.743          1      0.995      0.852\n",
            "                 truck          5         12      0.873        0.5      0.546      0.381\n",
            "                  boat          2          6      0.487      0.333      0.544      0.327\n",
            "         traffic light          4         14      0.452      0.143      0.188      0.138\n",
            "             stop sign          2          2      0.711          1      0.995      0.647\n",
            "                 bench          5          9      0.601      0.333      0.633      0.456\n",
            "                  bird          2         16      0.928      0.807      0.948       0.64\n",
            "                   cat          4          4       0.85          1      0.995      0.778\n",
            "                   dog          9          9      0.551      0.889      0.923       0.75\n",
            "                 horse          1          2      0.554          1      0.995      0.597\n",
            "              elephant          4         17      0.739      0.882      0.906      0.738\n",
            "                  bear          1          1      0.568          1      0.995      0.995\n",
            "                 zebra          2          4      0.859          1      0.995      0.965\n",
            "               giraffe          4          9      0.886          1      0.973      0.744\n",
            "              backpack          4          6      0.611      0.333      0.413      0.287\n",
            "              umbrella          4         18      0.618      0.629      0.692      0.475\n",
            "               handbag          9         19      0.548      0.105      0.305      0.173\n",
            "                   tie          6          7      0.674      0.714      0.754      0.541\n",
            "              suitcase          2          4      0.739          1      0.895      0.637\n",
            "               frisbee          5          5      0.695        0.8      0.759      0.679\n",
            "                  skis          1          1       0.87          1      0.995      0.497\n",
            "             snowboard          2          7      0.423      0.571      0.749      0.544\n",
            "           sports ball          6          6      0.668      0.336      0.492      0.336\n",
            "                  kite          2         10      0.674        0.4      0.588      0.199\n",
            "          baseball bat          4          4      0.603       0.25      0.414      0.248\n",
            "        baseball glove          4          7      0.855      0.429      0.431      0.303\n",
            "            skateboard          3          5      0.778        0.6       0.62      0.416\n",
            "         tennis racket          5          7      0.571      0.387      0.568      0.331\n",
            "                bottle          6         18      0.574      0.333      0.395      0.259\n",
            "            wine glass          5         16      0.607      0.438      0.635      0.363\n",
            "                   cup         10         36      0.646      0.389      0.491      0.364\n",
            "                  fork          6          6      0.586      0.167      0.242      0.217\n",
            "                 knife          7         16       0.63      0.625      0.623      0.374\n",
            "                 spoon          5         22      0.656      0.348      0.405      0.251\n",
            "                  bowl          9         28      0.596       0.75      0.745      0.604\n",
            "                banana          1          1          0          0      0.249     0.0329\n",
            "              sandwich          2          2      0.754          1      0.995      0.995\n",
            "                orange          1          4       0.76          1      0.895      0.607\n",
            "              broccoli          4         11      0.586      0.273      0.336      0.261\n",
            "                carrot          3         24      0.636      0.833      0.808      0.515\n",
            "               hot dog          1          2      0.505          1      0.995      0.995\n",
            "                 pizza          5          5      0.868          1      0.995      0.866\n",
            "                 donut          2         14      0.572          1      0.913      0.808\n",
            "                  cake          4          4      0.792          1      0.995       0.89\n",
            "                 chair          9         35      0.542      0.486       0.49      0.309\n",
            "                 couch          5          6      0.814      0.667      0.855      0.656\n",
            "          potted plant          9         14      0.621      0.702      0.742      0.526\n",
            "                   bed          3          3      0.861          1      0.995       0.83\n",
            "          dining table         10         13      0.512      0.615      0.588      0.474\n",
            "                toilet          2          2          1      0.915      0.995      0.946\n",
            "                    tv          2          2      0.766          1      0.995      0.895\n",
            "                laptop          2          3      0.773      0.667      0.806      0.698\n",
            "                 mouse          2          2          1          0     0.0452    0.00452\n",
            "                remote          5          8      0.755        0.5      0.608      0.522\n",
            "            cell phone          5          8      0.315      0.125       0.12     0.0717\n",
            "             microwave          3          3       0.67      0.667      0.913      0.749\n",
            "                  oven          5          5      0.513      0.427       0.52      0.383\n",
            "                  sink          4          6      0.396      0.167      0.309      0.192\n",
            "          refrigerator          5          5       0.69      0.455      0.795       0.64\n",
            "                  book          6         29      0.666      0.207      0.442       0.23\n",
            "                 clock          8          9      0.879      0.812        0.9      0.783\n",
            "                  vase          2          2      0.522          1      0.995      0.945\n",
            "              scissors          1          1          1          0      0.199     0.0254\n",
            "            teddy bear          6         21      0.716      0.619      0.705      0.466\n",
            "            toothbrush          2          5      0.977        0.8      0.962      0.673\n",
            "Speed: 1.5ms preprocess, 231.6ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/train/yolov8_coco1282\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'box_loss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'box_loss'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3425662746.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Plotar a perda (Loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"box_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Box Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obj_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Objectness Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Class Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'box_loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importar a biblioteca necess√°ria\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Baixar o modelo YOLOv8 pr√©-treinado\n",
        "# (Isso ser√° usado como base para o treinamento)\n",
        "model = YOLO(\"yolov8n.pt\")  # Modelo nano, r√°pido e leve. Pode usar \"yolov8s.pt\" para um modelo maior.\n",
        "\n",
        "# Treinar o modelo com o dataset COCO128\n",
        "# O COCO128 j√° est√° incluso no YOLO e n√£o precisa de download externo\n",
        "model.train(\n",
        "    data=\"coco128.yaml\",  # Dataset padr√£o inclu√≠do no YOLOv8\n",
        "    epochs=10,            # Ajuste o n√∫mero de √©pocas conforme necess√°rio\n",
        "    imgsz=640,            # Tamanho das imagens\n",
        "    batch=16,             # Tamanho do lote\n",
        "    project=\"runs/train\", # Local para salvar os resultados\n",
        "    name=\"yolov8_coco128\" # Nome do treinamento\n",
        ")\n",
        "\n",
        "# Validar o modelo treinado\n",
        "metrics = model.val()\n",
        "\n",
        "# Exibir resultados gr√°ficos e m√©tricas do treinamento\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Ler os resultados do CSV gerado pelo treinamento\n",
        "results_path = \"runs/train/yolov8_coco128/results.csv\"\n",
        "results = pd.read_csv(results_path)\n",
        "\n",
        "# Plotar a perda (Loss)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results[\"epoch\"], results[\"box_loss\"], label=\"Box Loss\")\n",
        "plt.plot(results[\"epoch\"], results[\"obj_loss\"], label=\"Objectness Loss\")\n",
        "plt.plot(results[\"epoch\"], results[\"cls_loss\"], label=\"Class Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotar mAP\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results[\"epoch\"], results[\"metrics/mAP_0.5\"], label=\"mAP 0.5\")\n",
        "plt.plot(results[\"epoch\"], results[\"metrics/mAP_0.5:0.95\"], label=\"mAP 0.5:0.95\")\n",
        "plt.title(\"mAP Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"mAP\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Mostrar as primeiras 5 imagens com predi√ß√µes do modelo\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "image_paths = glob.glob(\"runs/predict/val/*.jpg\")[:5]  # Ajuste conforme necess√°rio\n",
        "for img_path in image_paths:\n",
        "    img = Image.open(img_path)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ]
    }
  ]
}